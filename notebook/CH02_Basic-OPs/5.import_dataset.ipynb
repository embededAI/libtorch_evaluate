{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "after-exception",
   "metadata": {},
   "source": [
    "> 对于训练而言，批量加载训练数据是个基本的工作。如果使用PyTorch，以及python语言去编程，在数据集导入这块儿，比如读取csv文件，我们可以方便的使用pandas库去加载数据，对libtorch而言，虽然没有pandas类库，但是官方还是提供了一些方便的接口函数供大家使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "numerous-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <vector>  \n",
    "#include <list>\n",
    "#include <tuple>\n",
    "#include <fstream>\n",
    "\n",
    "/*a workaround to solve cling issue*/\n",
    "#include \"../macos_cling_workaround.hpp\"\n",
    "/*set libtorch path, load libs*/\n",
    "#include \"../load_libtorch.hpp\"\n",
    "/*set opencv4 path, load libs*/\n",
    "#include \"../load_opencv.hpp\"\n",
    "/*import custom defined macros*/\n",
    "#include \"../custom_def.hpp\"\n",
    "/*import libtorch header file*/\n",
    "#include <torch/torch.h>\n",
    "/*import opencv4*/\n",
    "#include <opencv2/opencv.hpp>\n",
    "\n",
    "std::cout << std::boolalpha;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-trinity",
   "metadata": {},
   "source": [
    "# 1.加载mnist数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-richardson",
   "metadata": {},
   "source": [
    "在libtorch官方例程中，提供了一个使用mnist数据集进行训练的[例子](https://pytorch.org/cppdocs/frontend.html)，其中关于加载数据集的代码如下:\n",
    "\n",
    "```\n",
    "\n",
    "  // Create a multi-threaded data loader for the MNIST dataset.\n",
    "  auto data_loader = torch::data::make_data_loader(\n",
    "      torch::data::datasets::MNIST(\"./data\").map(\n",
    "          torch::data::transforms::Stack<>()),\n",
    "      /*batch_size=*/64);\n",
    "\n",
    "\n",
    "  ...\n",
    "  ...\n",
    "  ...\n",
    "\n",
    "\n",
    "  for (size_t epoch = 1; epoch <= 10; ++epoch) {\n",
    "    size_t batch_index = 0;\n",
    "    // Iterate the data loader to yield batches from the dataset.\n",
    "    for (auto& batch : *data_loader) {\n",
    "      ...\n",
    "      ...\n",
    "      // Execute the model on the input data.\n",
    "      torch::Tensor prediction = net->forward(batch.data);\n",
    "      // Compute a loss value to judge the prediction of our model.\n",
    "      torch::Tensor loss = torch::nll_loss(prediction, batch.target);\n",
    "      ...\n",
    "      ...\n",
    "      // Output the loss and checkpoint every 100 batches.\n",
    "      if (++batch_index % 100 == 0) {\n",
    "        std::cout << \"Epoch: \" << epoch << \" | Batch: \" << batch_index\n",
    "                  << \" | Loss: \" << loss.item<float>() << std::endl;\n",
    "      ...\n",
    "      ...\n",
    "      ...\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "pending-removal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_train.is_train() = \n",
      "true\n",
      "<<--->>\n",
      "\n",
      "mnist_val.is_train() = \n",
      "false\n",
      "<<--->>\n",
      "\n",
      "mnist_train.images().dim() = \n",
      "4\n",
      "<<--->>\n",
      "\n",
      "dataset info(imgs * chan * rows * cols):\n",
      "60000 * 1 * 28 * 28\n",
      "\n",
      "mnist_train.targets().dim() = \n",
      "1\n",
      "<<--->>\n",
      "\n",
      "dataset info(targets):\n",
      "60000\n",
      "example.target = \n",
      "1\n",
      "[ CPULongType{} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//定义一个MNIST数据集句柄，默认为训练数据集\n",
    "auto mnist_train = torch::data::datasets::MNIST(\"../../dataset/mnist\"/*数据集路径*/);\n",
    "printT(mnist_train.is_train());\n",
    "\n",
    "//定义一个MNIST数据集句柄，指定为验证数据集\n",
    "auto mnist_val = torch::data::datasets::MNIST(\"../../dataset/mnist\", torch::data::datasets::MNIST::Mode::kTest);\n",
    "printT(mnist_val.is_train());\n",
    "\n",
    "//加载好的图片存放在images()中\n",
    "printT(mnist_train.images().dim());\n",
    "\n",
    "auto s = mnist_train.images().sizes();\n",
    "\n",
    "std::cout << \"dataset info(imgs * chan * rows * cols):\" << std::endl;\n",
    "for(int i = 0; i < s.size(); i++) {\n",
    "    std::cout << s[i];\n",
    "    if (i < (s.size()-1)) std::cout << \" * \";\n",
    "}\n",
    "std::cout << std::endl << std::endl;\n",
    "\n",
    "\n",
    "//加载好的标注存放在targets()中\n",
    "printT(mnist_train.targets().dim());\n",
    "\n",
    "s = mnist_train.targets().sizes();\n",
    "\n",
    "std::cout << \"dataset info(targets):\" << std::endl;\n",
    "for(int i = 0; i < s.size(); i++) {\n",
    "    std::cout << s[i];\n",
    "    if (i < (s.size()-1)) std::cout << \" * \";\n",
    "}\n",
    "std::cout << std::endl;\n",
    "\n",
    "\n",
    "auto example = mnist_train.get(3);\n",
    "// printT(example.data);\n",
    "printT(example.target);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-contributor",
   "metadata": {},
   "source": [
    "# 2.构造自定义Dataset\n",
    "\n",
    "注：本节参考[1](https://discuss.pytorch.org/t/libtorch-how-to-use-torch-datasets-for-custom-dataset/34221/2)， [2](https://github.com/mhubii/libtorch_custom_dataset/blob/master/custom_dataset.h) 以及libtorch中[MNIST的实现](https://github.com/pytorch/pytorch/blob/master/torch/csrc/api/src/data/datasets/mnist.cpp);\n",
    "\n",
    "\n",
    "*因为插件的限制，无法把所有代码归集到一个cell中执行，所以函数会写入多个cell，可能会比较分散，看官见谅；*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "designed-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch::Tensor parse_label_file(const std::string& label_file)\n",
    "{\n",
    "    torch::Tensor t_lab;\n",
    "    //open lable file, read out all labels\n",
    "    ///*/ label file format:\n",
    "    ///*/ obj_cls,x,y,width,height\n",
    "    ///*/ obj_cls : object class\n",
    "    ///*/ x,y     : left-top point position\n",
    "    ///*/ width   : width of anchor\n",
    "    ///*/ height  : height of anchor\n",
    "    \n",
    "    return t_lab;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "temporal-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "typedef std::tuple<torch::Tensor,torch::Tensor> data_sample;\n",
    "typedef std::vector<data_sample> data_sample_list;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "absent-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "//写一个用于加载数据的接口函数，此处我们假想数据存储方式类似MSCOCO数据集，即图片和标注都存在一个txt文件中：\n",
    "//即一行图片一行标注；\n",
    "//加载数据集时，只需制定这个txt文件的路径即可；\n",
    "data_sample_list read_data(const std::string& file_path) \n",
    "{\n",
    "    std::fstream in(file_path, std::ios::in);\n",
    "    std::string line;\n",
    "    std::string name;\n",
    "    std::string label;\n",
    "    int line_idx = 0;\n",
    "    data_sample_list sample_list;\n",
    "    \n",
    "    torch::Tensor t_img, t_lab;\n",
    "    while (std::getline(in, line))\n",
    "    {\n",
    "      if (0 == line_idx % 2) {\n",
    "        //读取到图片文件路径，将图片读取到并转成torch::Tensor\n",
    "        cv::Mat image = cv::imread(line);\n",
    "        /*\n",
    "         * !!!\n",
    "         * 由于xeus-cling插件问题，from_blob(...)在编译时会报错，因此本\n",
    "         * 例子无法在jupyter notebook中演示，建议单独写cpp文件并用gcc\n",
    "         * 编译；\n",
    "         * !!!\n",
    "         */\n",
    "        t_img = torch::from_blob(image.data, {image.rows, image.cols, 3}, torch::kByte).clone();\n",
    "      } else {\n",
    "        //读取到label文件路径，将数据读取到并存成torch::Tensor\n",
    "        t_lab = parse_label_file(line);\n",
    "      }\n",
    "      \n",
    "      data_sample d(t_img, t_lab);\n",
    "      sample_list.push_back(d);\n",
    "      line_idx ++;\n",
    "    }\n",
    "    \n",
    "    return sample_list;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "burning-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewDataset : public torch::data::Dataset<NewDataset>\n",
    "{\n",
    "  private:\n",
    "    //定义images和label，仿照MNIST\n",
    "    //std::list<std::tuple<torch::Tensor/*image*/, torch::Tensor/*label*/>> \n",
    "    data_sample_list dataset_;\n",
    "\n",
    "  public:\n",
    "    //file_path 是数据集描述文件，里面存放着图片以及对应label文件的路径\n",
    "    explicit NewDataset(const std::string& file_path/*csv or txt file*/)\n",
    "    : dataset_(read_data(file_path)) {  };\n",
    "\n",
    "    torch::data::Example<> get(size_t index) override {\n",
    "      // You may for example also read in a .csv file that stores locations\n",
    "      // to your data and then read in the data at this step. Be creative.\n",
    "      return {std::get<0>(dataset_[index]), std::get<1>(dataset_[index])};\n",
    "    }\n",
    "    \n",
    "    // Override the size method to infer the size of the data set.\n",
    "    torch::optional<size_t> size() const override {\n",
    "        return dataset_.size();\n",
    "    };\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "supreme-details",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IncrementalExecutor::executeFunction: symbol '__emutls_v._ZSt11__once_call' unresolved while linking function '_GLOBAL__sub_I_cling_module_19'!\n",
      "IncrementalExecutor::executeFunction: symbol '__emutls_v._ZSt15__once_callable' unresolved while linking function '_GLOBAL__sub_I_cling_module_19'!\n"
     ]
    }
   ],
   "source": [
    "//定义好的数据集可以使用data_loader进行加载\n",
    "// Generate your data set. At this point you can add transforms to you data set, e.g. stack your\n",
    "// batches into a single tensor.\n",
    "std::string file_path = \"../../dataset/ch02_samples/alldata.txt\"; //此处填入数据文件地址\n",
    "auto data_set = NewDataset(file_path).map(torch::data::transforms::Stack<>());\n",
    "int batch_size = 64;\n",
    "\n",
    "// Generate a data loader.\n",
    "auto data_loader = torch::data::make_data_loader<torch::data::samplers::SequentialSampler>(\n",
    "    std::move(data_set), \n",
    "    batch_size);\n",
    "\n",
    "// // In a for loop you can now use your data.\n",
    "// for (auto& batch : data_loader) {\n",
    "//     auto data = batch.data;\n",
    "//     auto labels = batch.target;\n",
    "//     // do your usual stuff\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-stamp",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
