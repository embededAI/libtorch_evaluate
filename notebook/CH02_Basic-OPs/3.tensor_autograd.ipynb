{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "circular-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include \"stdio.h\"\n",
    "#include \"stdlib.h\"\n",
    "#include <iostream>\n",
    "#include <vector>\n",
    "\n",
    "/*a workaround to solve cling issue*/\n",
    "#include \"../macos_cling_workaround.hpp\"\n",
    "/*set libtorch path, load libs*/\n",
    "#include \"../load_libtorch.hpp\"\n",
    "/*import custom defined macros*/\n",
    "#include \"../custom_def.hpp\"\n",
    "/*import libtorch header file*/\n",
    "#include <torch/torch.h>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-cocktail",
   "metadata": {},
   "source": [
    "***自动求梯度是PyTorch非常有特色的一项功能，不论是机器学习还是深度学习，我们经常需要对函数求梯度，特别是深度神经网络在执行反向传播操作时，求梯度是必备功能之一。***\n",
    "\n",
    "***PyTorch提供的autograd包能够根据输入和前向传播过程自动构建计算图，并执行反向传播。***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-irrigation",
   "metadata": {},
   "source": [
    "# 1. 简单示例\n",
    "\n",
    "下面先通过一些例子看看autograd功能是如何使用的(注：此处我们并不完全按照“dive into DL pytorch”教程中的方式来，而是结合了[官方教程](https://pytorch.org/tutorials/advanced/cpp_autograd.html))："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "pacific-dating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = \n",
      " 1  1\n",
      " 1  1\n",
      "[ CPUFloatType{2,2} ]\n",
      "<<--->>\n",
      "\n",
      "x.grad_fn()->name() = \n",
      "AddBackward1\n",
      "<<--->>\n",
      "\n",
      "y = \n",
      " 27  27\n",
      " 27  27\n",
      "[ CPUFloatType{2,2} ]\n",
      "<<--->>\n",
      "\n",
      "y.grad_fn()->name() = \n",
      "MulBackward1\n",
      "<<--->>\n",
      "\n",
      "out = \n",
      "27\n",
      "[ CPUFloatType{} ]\n",
      "<<--->>\n",
      "\n",
      "out.grad_fn()->name() = \n",
      "MeanBackward0\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// std::cout << std::boolalpha;\n",
    "\n",
    "//创建一个Tensor并设置requires_grad=true去跟踪其计算过程:\n",
    "torch::Tensor x = torch::ones({2,2}, torch::requires_grad(true));\n",
    "printT(x);\n",
    "\n",
    "x = x+2;\n",
    "//对于tensor加法而言，其梯度函数为：AddBackward1\n",
    "printT(x.grad_fn()->name());\n",
    "\n",
    "\n",
    "//如果上面参数torch::requires_grad设置为false，则上面语句会报错：\n",
    "//null passed to a callee that requires a non-null argument [-Wnonnull]\n",
    "\n",
    "\n",
    "auto y = x * x *3;\n",
    "auto out = y.mean();\n",
    "\n",
    "printT(y);\n",
    "printT(y.grad_fn()->name());\n",
    "\n",
    "printT(out);\n",
    "printT(out.grad_fn()->name());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-assembly",
   "metadata": {},
   "source": [
    "初始化Tensor后再修改其autograd属性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "hungry-sheffield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.requires_grad() = \n",
      "false\n",
      "<<--->>\n",
      "\n",
      "a.requires_grad() = \n",
      "true\n",
      "<<--->>\n",
      "\n",
      "b.grad_fn()->name() = \n",
      "SumBackward0\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std::cout << std::boolalpha;\n",
    "\n",
    "auto a = torch::randn({2, 2});\n",
    "a = ((a * 3) / (a - 1));\n",
    "printT(a.requires_grad());\n",
    "\n",
    "a.requires_grad_(true);\n",
    "printT(a.requires_grad());\n",
    "\n",
    "auto b = (a * a).sum();\n",
    "printT(b.grad_fn()->name());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "compressed-poultry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad() = \n",
      " 4.5000  4.5000\n",
      " 4.5000  4.5000\n",
      "[ CPUFloatType{2,2} ]\n",
      "<<--->>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//再回到刚开始那个例子，给out变量做一次反向传播运算，看看其梯度是多少\n",
    "torch::Tensor x = torch::ones({2,2}, torch::requires_grad(true));\n",
    "auto y = x+2;\n",
    "auto z = y * y *3;\n",
    "auto out = z.mean();\n",
    "//求梯度，只能针对scalar类型的变量进行\n",
    "out.backward();\n",
    "\n",
    "printT(x.grad());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-timing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
