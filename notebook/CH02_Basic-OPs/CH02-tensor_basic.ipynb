{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cheap-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include \"stdio.h\"\n",
    "#include \"stdlib.h\"\n",
    "#include <iostream>\n",
    "\n",
    "/*a workaround to solve cling issue*/\n",
    "#include \"../macos_cling_workaround.hpp\"\n",
    "/*set libtorch path, load libs*/\n",
    "#include \"../load_libtorch.hpp\"\n",
    "#include <torch/torch.h>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-dinner",
   "metadata": {},
   "source": [
    "# 1.创建一个Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-project",
   "metadata": {},
   "source": [
    "创建未初始化的tensor："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "electrical-hopkins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7.3111e+18\n",
      " 3.5543e+18\n",
      " 8.0309e+18\n",
      "[ CPULongType{3} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor t1 = torch::empty(3, torch::kInt64);\n",
    "\n",
    "std::cout << t1 << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handmade-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.7050e+08  2.1851e+04  0.0000e+00  0.0000e+00  9.0000e+00  1.2322e+09\n",
      " 1.2634e+09  9.0921e+08  1.9531e+09  1.7687e+09  1.6013e+09  1.9537e+09\n",
      " 8.7696e+08  1.7025e+09  1.9126e+09  1.5993e+09  1.6000e+02  0.0000e+00\n",
      " 8.0000e+01  0.0000e+00 -5.6166e+08  2.1851e+04  0.0000e+00  0.0000e+00\n",
      " 1.0000e+01  1.9524e+09  1.2634e+09  9.0921e+08  1.9531e+09  1.7687e+09\n",
      "[ CPUIntType{5,6} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor t2 = torch::empty({5,6}, torch::kInt32);\n",
    "std::cout << t2 << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "foreign-italian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,.,.) = \n",
      "  101  102\n",
      "  105  110\n",
      "  101  100\n",
      "   84  101\n",
      "\n",
      "(2,.,.) = \n",
      "  110  115\n",
      "  111  114\n",
      "   73  109\n",
      "  112  108\n",
      "\n",
      "(3,.,.) = \n",
      "   69   69\n",
      "   55  114\n",
      "  101  116\n",
      "   97  105\n",
      "[ CPUCharType{3,4,2} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor t3 = torch::empty({3,4,2}, torch::kInt8);\n",
    "std::cout << t3 << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-stocks",
   "metadata": {},
   "source": [
    "创建值为0的tensor："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "local-shock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[ CPUFloatType{3,4} ]\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[ CPUIntType{3,4} ]\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::zeros({3, 4});\n",
    "std::cout << x << std::endl;\n",
    "\n",
    "torch::Tensor y = torch::zeros({3, 4}, torch::kInt);\n",
    "std::cout << y << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-labor",
   "metadata": {},
   "source": [
    "创建值为随机数的tensor："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rolled-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.4444  0.7839  0.3972  0.5826\n",
      " 0.8967  0.1082  0.5972  0.1979\n",
      " 0.5112  0.3519  0.5890  0.8016\n",
      "[ CPUFloatType{3,4} ]\n",
      "<<<=========>>>\n",
      "\n",
      " 0.3386  0.7420  0.4815  0.3888\n",
      " 0.8127  0.1300  0.6292  0.4419\n",
      " 0.7200  0.4255  0.8997  0.3681\n",
      "[ CPUDoubleType{3,4} ]\n",
      "<<<=========>>>\n",
      "\n",
      "(1,.,.) = \n",
      " -0.2787  1.2748  0.8307  0.9763\n",
      " -0.3594 -1.1021 -0.6364 -0.0364\n",
      "  0.7180  0.0749 -0.0436 -2.4029\n",
      "\n",
      "(2,.,.) = \n",
      " -0.2440 -0.0459  0.8772 -0.9237\n",
      " -1.6146 -0.5144 -0.0731  0.2669\n",
      " -0.5208 -0.0864  0.9103  0.8287\n",
      "\n",
      "(3,.,.) = \n",
      " -0.8943 -1.7940  0.0125  1.6025\n",
      " -2.0548  0.3773  1.4870  0.5982\n",
      " -0.0344  0.8939  1.7970  0.5809\n",
      "\n",
      "(4,.,.) = \n",
      "  1.1613 -1.6727 -1.1365  1.2555\n",
      " -0.1700  0.2928  1.7869 -0.2510\n",
      "  0.2229  2.3172 -2.0089 -0.7028\n",
      "\n",
      "(5,.,.) = \n",
      " -0.1174 -0.4590 -0.6379  0.7281\n",
      "  0.0454  0.5225 -0.3091  1.8815\n",
      "  0.1755 -1.0258 -0.2639  0.5765\n",
      "[ CPUFloatType{5,3,4} ]\n",
      "<<<=========>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::rand({3, 4});\n",
    "std::cout << x << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor y = torch::rand({3, 4}, torch::kFloat64);\n",
    "std::cout << y << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "torch::Tensor z = torch::randn({5, 3, 4}, torch::kFloat32);\n",
    "std::cout << z << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-comparative",
   "metadata": {},
   "source": [
    "根据已有tensor创建新的tensor："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imperial-georgia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3  3  3\n",
      " 3  3  3\n",
      " 3  3  3\n",
      "[ CPUFloatType{3,3} ]\n",
      "<<<=========>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor t = torch::ones({3,3});\n",
    "t += 2;\n",
    "\n",
    "\n",
    "torch::Tensor a(t);\n",
    "std::cout << a << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "respective-karen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.1059  1.7008 -1.0940\n",
      " 0.6755 -0.5386 -1.5082\n",
      " 0.5866  0.4006  1.7089\n",
      "-0.3359  0.1243 -0.2685\n",
      " 1.2250 -1.8495  0.8217\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<<=========>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor a = torch::ones({5,3});\n",
    "a = torch::randn_like(a);\n",
    "\n",
    "std::cout << a << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-sapphire",
   "metadata": {},
   "source": [
    "# 2. Tensor的相关运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-rates",
   "metadata": {},
   "source": [
    "## 加法运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "national-coating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[ CPUFloatType{5,3} ]\n",
      "\n",
      "y =\n",
      "-0.4262  0.2588 -1.2324\n",
      " 1.5842 -1.4629  0.5925\n",
      "-0.2029  0.6585 -0.0634\n",
      " 2.2986 -0.6072  0.9584\n",
      " 2.4718  1.3781  1.0643\n",
      "[ CPUFloatType{5,3} ]\n",
      "\n",
      "x+y =\n",
      " 0.5738  1.2588 -0.2324\n",
      " 2.5842 -0.4629  1.5925\n",
      " 0.7971  1.6585  0.9366\n",
      " 3.2986  0.3928  1.9584\n",
      " 3.4718  2.3781  2.0643\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<<=========>>>\n",
      "\n",
      "torch::add(x,y) =\n",
      " 0.5738  1.2588 -0.2324\n",
      " 2.5842 -0.4629  1.5925\n",
      " 0.7971  1.6585  0.9366\n",
      " 3.2986  0.3928  1.9584\n",
      " 3.4718  2.3781  2.0643\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<<=========>>>\n",
      "\n",
      "y.add_(x) =\n",
      " 0.5738  1.2588 -0.2324\n",
      " 2.5842 -0.4629  1.5925\n",
      " 0.7971  1.6585  0.9366\n",
      " 3.2986  0.3928  1.9584\n",
      " 3.4718  2.3781  2.0643\n",
      "[ CPUFloatType{5,3} ]\n",
      "<<<=========>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::ones({5,3});\n",
    "torch::Tensor y = torch::randn({5,3});\n",
    "\n",
    "std::cout << \"x =\" << std::endl;\n",
    "std::cout << (x) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"y =\" << std::endl;\n",
    "std::cout << (y) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"x+y =\" << std::endl;\n",
    "std::cout << (x+y) << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"torch::add(x,y) =\" << std::endl;\n",
    "std::cout << torch::add(x,y) << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"y.add_(x) =\" << std::endl;\n",
    "std::cout << y.add_(x) << std::endl;\n",
    "std::cout << \"<<<=========>>>\" << std::endl << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-essence",
   "metadata": {},
   "source": [
    "## 索引\n",
    "借助于torch::Tensor::index()和torch::Tensor::index_put_()函数，我们可以在libtorch中实现类似pytorch中对tensor的切片存取操作。具体说明详见[tensor_indexing](https://pytorch.org/cppdocs/notes/tensor_indexing.html)页面."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "compliant-chance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      "  0   1   2   3\n",
      "  4   5   6   7\n",
      "  8   9  10  11\n",
      "[ CPUFloatType{3,4} ]\n",
      "\n",
      "(in python) x[None]=\n",
      "(1,.,.) = \n",
      "   0   1   2   3\n",
      "   4   5   6   7\n",
      "   8   9  10  11\n",
      "[ CPUFloatType{1,3,4} ]\n",
      "\n",
      "(in python) x[Ellipsis, ...]=\n",
      "  0   1   2   3\n",
      "  4   5   6   7\n",
      "  8   9  10  11\n",
      "[ CPUFloatType{3,4} ]\n",
      "\n",
      "(in python) x[1,1]=\n",
      "5\n",
      "[ CPUFloatType{} ]\n",
      "\n",
      "(in python) x[True, False]=\n",
      "[ CPUFloatType{0,3,4} ]\n",
      "\n",
      "(in python) x[1::2]=\n",
      " 4  5  6  7\n",
      "[ CPUFloatType{1,4} ]\n",
      "\n",
      "(in python) x[::2]=\n",
      "  0   1   2   3\n",
      "  8   9  10  11\n",
      "[ CPUFloatType{2,4} ]\n",
      "\n",
      "y =\n",
      "  0   1   2   3   4   5\n",
      "  6   7   8   9  10  11\n",
      "[ CPUFloatType{2,6} ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch::Tensor x = torch::zeros({3,4});\n",
    "\n",
    "for (int i = 0; i < 3; i++) {\n",
    "    for (int j = 0; j < 4; j++) {\n",
    "        x[i][j] = i * 4 + j;\n",
    "    }\n",
    "}\n",
    "    \n",
    "std::cout << \"x =\" << std::endl;\n",
    "std::cout << (x) << std::endl << std::endl;\n",
    "\n",
    "/* *\n",
    " *  Getter ops\n",
    " */\n",
    "\n",
    "std::cout << \"(in python) x[None]=\" << std::endl;\n",
    "std::cout << (x.index({torch::indexing::None})) << std::endl << std::endl;\n",
    "\n",
    "\n",
    "std::cout << \"(in python) x[Ellipsis, ...]=\" << std::endl;\n",
    "std::cout << (x.index({torch::indexing::Ellipsis, \"...\"})) << std::endl << std::endl;\n",
    "\n",
    "\n",
    "std::cout << \"(in python) x[1,1]=\" << std::endl;\n",
    "std::cout << (x.index({1,1})) << std::endl << std::endl;\n",
    "\n",
    "\n",
    "std::cout << \"(in python) x[True, False]=\" << std::endl;\n",
    "std::cout << (x.index({true, false})) << std::endl << std::endl;\n",
    "\n",
    "\n",
    "std::cout << \"(in python) x[1::2]=\" << std::endl;\n",
    "std::cout << (x.index({torch::indexing::Slice(1, torch::indexing::None, 2)})) << std::endl << std::endl;\n",
    "\n",
    "std::cout << \"(in python) x[::2]=\" << std::endl;\n",
    "std::cout << (x.index({torch::indexing::Slice(torch::indexing::None, torch::indexing::None, 2)})) << std::endl << std::endl;\n",
    "\n",
    "\n",
    "\n",
    "torch::Tensor y = x.view({2, -1});\n",
    "std::cout << \"y =\" << std::endl;\n",
    "std::cout << (y) << std::endl << std::endl;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-scholarship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "effective-college",
   "metadata": {},
   "source": [
    "# 3. 引申内容 - Part 1：PYTORCH C++ API的组成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-tuesday",
   "metadata": {},
   "source": [
    "截止到PyTorch 1.7.1版本，其C++ API由5大部分组成，如下表所示：\n",
    "\n",
    "| 命名空间 | 功能描述  |\n",
    "| :----: | :---- |\n",
    "| **ATen**   | The foundational tensor and mathematical operation library on which all else is built. |\n",
    "| **Autograd**   | Augments ATen with automatic differentiation. |\n",
    "| **C++ Frontend**   | High level constructs for training and evaluation of machine learning models. |\n",
    "| **TorchScript**   | An interface to the TorchScript JIT compiler and interpreter. |\n",
    "| **C++ Extensions**   | A means of extending the Python API with custom C++ and CUDA routines. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-proxy",
   "metadata": {},
   "source": [
    "## ATen\n",
    "ATen是一个基础的tensor库，PyTorch中Python和C++接口函数都是构建在这个库的基础上的。它提供了一个Tensor类，在这个类中定义了上百中tensor的相关操作，多数操作可以同时支持CPU和GPU实现，Tensor类可以根据数据类型来动态指定在哪种处理器上执行操作。其命名空间为at::。下面是个简单的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "seventh-shannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = \n",
      " 1  1\n",
      " 1  1\n",
      "[ CPUIntType{2,2} ]\n",
      "b = \n",
      " 0.1778 -0.3870\n",
      "-3.1225 -0.3888\n",
      "[ CPUFloatType{2,2} ]\n",
      "c = \n",
      " 1  1\n",
      "-2  1\n",
      "[ CPUIntType{2,2} ]\n"
     ]
    }
   ],
   "source": [
    "#include <ATen/ATen.h>\n",
    "\n",
    "at::Tensor a = at::ones({2, 2}, at::kInt);\n",
    "std::cout << \"a = \" << std::endl << a << std::endl;\n",
    "at::Tensor b = at::randn({2, 2}, at::kFloat);\n",
    "std::cout << \"b = \" << std::endl << b << std::endl;\n",
    "auto c = a + b.to(at::kInt);\n",
    "std::cout << \"c = \" << std::endl << c << std::endl;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-unknown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "autograd是PyTorch C++ API的一部分，属于对ATen的Tensor类的功能增强，使其具备自动化微分功能。autograd系统会记录tensor上的操作，进而形成一个autograd graph。调用tensor变量的backwards()函数会产生逆向的差分运算。\n",
    "注意：ATen中的at::Tensor类默认并不具备微分功能。为了使tensors具备可微分功能，你必须使用tensor的工厂方法，即调用torch::命名空间的函数，而不是去直接调用at::命名空间的函数。比如，at::ones()函数产生的tensor是不具备可微分功能的，但是torch::ones()函数的就可以。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-berlin",
   "metadata": {},
   "source": [
    "## C++ Frontend\n",
    "PyTorch C++前端框架为神经网络和通用机器学习提供了一套纯C++的模型接口，包括：\n",
    "* 用于自定义机器学习模型的层级模型接口系统；\n",
    "* 为构建深度学习模型的常见函数库，如卷积运算，RNN，BN等；\n",
    "* 深度学习优化方法API，如SGD,Adam,RMSprop等；\n",
    "* 一种数据集和数据管道的表示方式；\n",
    "* 序列化存储和加载训练过程中checkpoints的格式；\n",
    "* 在多GPU上并行运行模型；\n",
    "* TorchScript JIT compiler的接入口；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-eugene",
   "metadata": {},
   "source": [
    "## TorchScript\n",
    "这是对PyTorch模型的一种表示方法。事实上，TorchScript在某种意义上是一种编程语言，是Python的一个子集。TorchScript的C++接口包含的主要功能有：\n",
    "* 加载和运行序列化TorchScript模型；\n",
    "* 提供相关API，使用户可以自定义算子；\n",
    "* TorchScript C++程序的即时编译；\n",
    "\n",
    "对于第一个功能而言，这个给用户提供了一种方法，即开发者可以使用python来编写算法并训练，训练得到的模型参数可以直接用于C++程序中，而无需使用libtorch重新编写深度学习模型并从头训练。（听着不错，但实测发现有某种程度的精度损失）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-bulletin",
   "metadata": {},
   "source": [
    "## C++ Extensions\n",
    "C++扩展提供了一种简单而有效的方法，使得开发者可以方便的访问PyTorch的上层接口。其最常见的用法是让开发者可以自定义算子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-complexity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
